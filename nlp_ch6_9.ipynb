{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp ch6~9",
      "provenance": [],
      "collapsed_sections": [
        "MSW_G8095ghH",
        "zbdX5qBQ5ktD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSW_G8095ghH",
        "colab_type": "text"
      },
      "source": [
        "#SVD 실습\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvqcHvM737fq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32fefb8f-a0af-482b-c856-c389b9f85d32"
      },
      "source": [
        "import numpy as np\n",
        "A=np.array([[0,0,0,1,0,1,1,0,0],[0,0,0,1,1,0,1,0,0],[0,1,1,0,2,0,0,0,0],[1,0,0,0,0,0,0,1,1]])\n",
        "np.shape(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "611eg61F3_ps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4083f4aa-c993-47e3-9d8f-fd3cbaa29a6b"
      },
      "source": [
        "U, s, VT = np.linalg.svd(A, full_matrices = True)\n",
        "\n",
        "print(U.round(2)) #.round(2) 소숫점 둘째자리까지만 출력.\n",
        "np.shape(U)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.24  0.75  0.   -0.62]\n",
            " [-0.51  0.44 -0.    0.74]\n",
            " [-0.83 -0.49 -0.   -0.27]\n",
            " [-0.   -0.    1.    0.  ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNhMoZSM4GDw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4702d1d-d948-45ec-fa26-c5e74096a772"
      },
      "source": [
        "print(s.round(2))\n",
        "np.shape(s)\n",
        "\n",
        "'''Numpy의 linalg.svd()는 특이값 분해의 결과로 대각 행렬이 아니라 특이값의 리스트를 반환합니다. \n",
        "그러므로 앞서 본 수식의 형식으로 보려면 이를 다시 대각 행렬로 바꾸어 주어야 합니다. \n",
        "우선 특이값을 s에 저장하고 대각 행렬 크기의 행렬을 생성한 후에 그 행렬에 특이값을 삽입해도록 하겠습니다.'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.69 2.05 1.73 0.77]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Numpy의 linalg.svd()는 특이값 분해의 결과로 대각 행렬이 아니라 특이값의 리스트를 반환합니다. \\n그러므로 앞서 본 수식의 형식으로 보려면 이를 다시 대각 행렬로 바꾸어 주어야 합니다. \\n우선 특이값을 s에 저장하고 대각 행렬 크기의 행렬을 생성한 후에 그 행렬에 특이값을 삽입해도록 하겠습니다.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GmvjzGS4R1P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baddfa84-a038-459a-fcaf-29aa4073fbe1"
      },
      "source": [
        "S = np.zeros((4, 9)) # 대각 행렬의 크기인 4 x 9의 임의의 행렬 생성\n",
        "S[:4, :4] = np.diag(s) # 특이값을 대각행렬에 삽입\n",
        "print(S.round(2))\n",
        "np.shape(S)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.69 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   2.05 0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   1.73 0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.77 0.   0.   0.   0.   0.  ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEV3Hf1L4fej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09fccb15-b78d-4606-bde3-321c302cd894"
      },
      "source": [
        "print(VT.round(2))\n",
        "np.shape(VT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
            " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]\n",
            " [ 0.58 -0.    0.    0.   -0.    0.   -0.    0.58  0.58]\n",
            " [ 0.   -0.35 -0.35  0.16  0.25 -0.8   0.16 -0.   -0.  ]\n",
            " [-0.   -0.78 -0.01 -0.2   0.4   0.4  -0.2   0.    0.  ]\n",
            " [-0.29  0.31 -0.78 -0.24  0.23  0.23  0.01  0.14  0.14]\n",
            " [-0.29 -0.1   0.26 -0.59 -0.08 -0.08  0.66  0.14  0.14]\n",
            " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19  0.75 -0.25]\n",
            " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19 -0.25  0.75]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZXigF0y4t0j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4573c107-f510-41c1-cea4-3f36f0425a7b"
      },
      "source": [
        "'''9 × 9의 크기를 가지는 직교 행렬 VT(V의 전치 행렬)가 생성되었습니다. 즉, U × S × VT를 하면 기존의 행렬 A가 나와야 합니다. \n",
        "Numpy의 allclose()는 2개의 행렬이 동일하면 True를 리턴합니다. 이를 사용하여 정말로 기존의 행렬 A와 동일한지 확인해보겠습니다.'''\n",
        "np.allclose(A, np.dot(np.dot(U,S), VT).round(2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_F_Zgsz455P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec103c4-87b1-4df1-a9fd-52e5790daabe"
      },
      "source": [
        "U=U[:,:2]\n",
        "print(U.round(2))\n",
        "\n",
        "VT=VT[:2,:]\n",
        "print(\"\\n\",VT.round(2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.24  0.75]\n",
            " [-0.51  0.44]\n",
            " [-0.83 -0.49]\n",
            " [-0.   -0.  ]]\n",
            "\n",
            " [[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
            " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbdX5qBQ5ktD",
        "colab_type": "text"
      },
      "source": [
        "#실습을 통한 이해"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z95CEMYx5Edb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d92c6be-605c-4cc7-86f4-be8b5bb2f544"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
        "documents = dataset.data\n",
        "len(documents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11314"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k836YRQP5np1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ddc0e94-c0fc-4a31-941d-1d16404c5f51"
      },
      "source": [
        "documents[1]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWd1E3Nd5tbT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fe03127-0e8f-496e-edac-a934d8807888"
      },
      "source": [
        "'''뉴스그룹 데이터에는 특수문자가 포함된 다수의 영어문장으로 구성되어져 있습니다. 이런 형식의 샘플이 총 11,314개 존재합니다. \n",
        "사이킷런이 제공하는 뉴스그룹 데이터에서 target_name에는 본래 이 뉴스그룹 데이터가 어떤 20개의 카테고리를 갖고있었는지가 저장되어져 있습니다. \n",
        "이를 출력해보겠습니다.'''\n",
        "\n",
        "print(dataset.target_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFBeqnc-5_fp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''시작하기 앞서, 텍스트 데이터에 대해서 가능한한 정제 과정을 거쳐야만 합니다. \n",
        "기본적인 아이디어는 알파벳을 제외한 구두점, 숫자, 특수 문자를 제거하는 것입니다. \n",
        "이는 텍스트 전처리 챕터에서 정제 기법으로 배웠던 정규 표현식을 통해서 해결할 수 있습니다. \n",
        "또한 짧은 단어는 유용한 정보를 담고있지 않다고 가정하고, 길이가 짧은 단어도 제거합니다. \n",
        "그리고 마지막으로 모든 알파벳을 소문자로 바꿔서 단어의 개수를 줄이는 작업을 합니다.'''\n",
        "\n",
        "news_df = pd.DataFrame({'document':documents})\n",
        "# 특수 문자 제거\n",
        "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n",
        "# 길이가 3이하인 단어는 제거 (길이가 짧은 단어 제거)\n",
        "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
        "# 전체 단어에 대한 소문자 변환\n",
        "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp2qg5lv6ORj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d00256-63fe-4584-f3c0-c131d92b11ca"
      },
      "source": [
        "news_df['clean_doc'][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'yeah expect people read actually accept hard atheism need little leap faith jimmy your logic runs steam sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway maybe start newsgroup atheist hard bummin much forget your flintstone chewables bake timmons'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhKjwY146ncz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "643b0072-fa7c-4c33-cec4-1da0c7bd6fd3"
      },
      "source": [
        "import nltk\n",
        "nltk.download('popular')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxCF92_Y6QTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "우선 특수문자가 제거되었으며, if나 you와 같은 길이가 3이하인 단어가 제거된 것을 확인할 수 있습니다. \n",
        "뿐만 아니라 대문자가 전부 소문자로 바뀌었습니다. \n",
        "이제 뉴스그룹 데이터에서 불용어를 제거합니다. 불용어를 제거하기 위해서 토큰화를 우선 수행합니다. \n",
        "토큰화와 불용어 제거를 순차적으로 진행합니다.'''\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english') # NLTK로부터 불용어를 받아옵니다.\n",
        "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split()) # 토큰화\n",
        "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
        "# 불용어를 제거합니다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EWxSNHi6lG9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93f0d1b-1227-4bb6-f6fa-b550f8951cf3"
      },
      "source": [
        "print(tokenized_doc[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['yeah', 'expect', 'people', 'read', 'actually', 'accept', 'hard', 'atheism', 'need', 'little', 'leap', 'faith', 'jimmy', 'logic', 'runs', 'steam', 'sorry', 'pity', 'sorry', 'feelings', 'denial', 'faith', 'need', 'well', 'pretend', 'happily', 'ever', 'anyway', 'maybe', 'start', 'newsgroup', 'atheist', 'hard', 'bummin', 'much', 'forget', 'flintstone', 'chewables', 'bake', 'timmons']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abrr54JE7La9",
        "colab_type": "text"
      },
      "source": [
        "#TF-IDF 행렬만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbeNSBnH6_RR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 역토큰화 (토큰화 작업을 역으로 되돌림)\n",
        "detokenized_doc = []\n",
        "for i in range(len(news_df)):\n",
        "    t = ' '.join(tokenized_doc[i])\n",
        "    detokenized_doc.append(t)\n",
        "\n",
        "news_df['clean_doc'] = detokenized_doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smRBItY97R-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0a46a3dc-e474-4248-bec0-cf1326a470e9"
      },
      "source": [
        "news_df['clean_doc'][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'yeah expect people read actually accept hard atheism need little leap faith jimmy logic runs steam sorry pity sorry feelings denial faith need well pretend happily ever anyway maybe start newsgroup atheist hard bummin much forget flintstone chewables bake timmons'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqrhbHjk7Thj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b58b5f78-93dc-4abd-c5eb-ea51611b952a"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english', \n",
        "max_features= 1000, # 상위 1,000개의 단어를 보존 \n",
        "max_df = 0.5, \n",
        "smooth_idf=True)\n",
        "\n",
        "X = vectorizer.fit_transform(news_df['clean_doc'])\n",
        "X.shape # TF-IDF 행렬의 크기 확인"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPjy8LE67aq9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef4b7ab8-722d-4c13-9eb8-0a770770bc61"
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "svd_model = TruncatedSVD(n_components=20, algorithm='randomized', n_iter=100, random_state=122)\n",
        "svd_model.fit(X)\n",
        "len(svd_model.components_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5u8yXzJ7iLM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d392ea22-370e-42d5-8bdc-3ac80b87b91c"
      },
      "source": [
        "#여기서 svd_model.componets_는 앞서 배운 LSA에서 VT에 해당됩니다.\n",
        "np.shape(svd_model.components_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0BsmAmI7l7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "923b24ac-f172-4fc4-f1e9-2db22f02bb2f"
      },
      "source": [
        "terms = vectorizer.get_feature_names() # 단어 집합. 1,000개의 단어가 저장됨.\n",
        "\n",
        "def get_topics(components, feature_names, n=5):\n",
        "    for idx, topic in enumerate(components):\n",
        "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])\n",
        "get_topics(svd_model.components_,terms)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 1: [('like', 0.21386), ('know', 0.20046), ('people', 0.19293), ('think', 0.17805), ('good', 0.15128)]\n",
            "Topic 2: [('thanks', 0.32888), ('windows', 0.29088), ('card', 0.18069), ('drive', 0.17455), ('mail', 0.15111)]\n",
            "Topic 3: [('game', 0.37064), ('team', 0.32443), ('year', 0.28154), ('games', 0.2537), ('season', 0.18419)]\n",
            "Topic 4: [('drive', 0.53324), ('scsi', 0.20165), ('hard', 0.15628), ('disk', 0.15578), ('card', 0.13994)]\n",
            "Topic 5: [('windows', 0.40399), ('file', 0.25436), ('window', 0.18044), ('files', 0.16078), ('program', 0.13894)]\n",
            "Topic 6: [('chip', 0.16114), ('government', 0.16009), ('mail', 0.15625), ('space', 0.1507), ('information', 0.13562)]\n",
            "Topic 7: [('like', 0.67086), ('bike', 0.14236), ('chip', 0.11169), ('know', 0.11139), ('sounds', 0.10371)]\n",
            "Topic 8: [('card', 0.46633), ('video', 0.22137), ('sale', 0.21266), ('monitor', 0.15463), ('offer', 0.14643)]\n",
            "Topic 9: [('know', 0.46047), ('card', 0.33605), ('chip', 0.17558), ('government', 0.1522), ('video', 0.14356)]\n",
            "Topic 10: [('good', 0.42756), ('know', 0.23039), ('time', 0.1882), ('bike', 0.11406), ('jesus', 0.09027)]\n",
            "Topic 11: [('think', 0.78469), ('chip', 0.10899), ('good', 0.10635), ('thanks', 0.09123), ('clipper', 0.07946)]\n",
            "Topic 12: [('thanks', 0.36824), ('good', 0.22729), ('right', 0.21559), ('bike', 0.21037), ('problem', 0.20894)]\n",
            "Topic 13: [('good', 0.36212), ('people', 0.33985), ('windows', 0.28385), ('know', 0.26232), ('file', 0.18422)]\n",
            "Topic 14: [('space', 0.39946), ('think', 0.23258), ('know', 0.18074), ('nasa', 0.15174), ('problem', 0.12957)]\n",
            "Topic 15: [('space', 0.31613), ('good', 0.3094), ('card', 0.22603), ('people', 0.17476), ('time', 0.14496)]\n",
            "Topic 16: [('people', 0.48156), ('problem', 0.19961), ('window', 0.15281), ('time', 0.14664), ('game', 0.12871)]\n",
            "Topic 17: [('time', 0.34465), ('bike', 0.27303), ('right', 0.25557), ('windows', 0.1997), ('file', 0.19118)]\n",
            "Topic 18: [('time', 0.5973), ('problem', 0.15504), ('file', 0.14956), ('think', 0.12847), ('israel', 0.10903)]\n",
            "Topic 19: [('file', 0.44163), ('need', 0.26633), ('card', 0.18388), ('files', 0.17453), ('right', 0.15448)]\n",
            "Topic 20: [('problem', 0.33006), ('file', 0.27651), ('thanks', 0.23578), ('used', 0.19206), ('space', 0.13185)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIzg0R9Y7rWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZE5X0V-HfTt",
        "colab_type": "text"
      },
      "source": [
        "# 잠재 디리클레 할당 실습2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z5s6LofHkUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/franciscadias/data/master/abcnews-date-text.csv\", filename=\"abcnews-date-text.csv\")\n",
        "data = pd.read_csv('abcnews-date-text.csv', error_bad_lines=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvQOT5-ZHmqV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1492501e-81d5-40a4-919a-a27bd99a1dd8"
      },
      "source": [
        "print(len(data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1082168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ3EP7RhHofg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "f785c108-9170-4b58-c9fa-f4612148720f"
      },
      "source": [
        "print(data.head(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   publish_date                                      headline_text\n",
            "0      20030219  aba decides against community broadcasting lic...\n",
            "1      20030219     act fire witnesses must be aware of defamation\n",
            "2      20030219     a g calls for infrastructure protection summit\n",
            "3      20030219           air nz staff in aust strike for pay rise\n",
            "4      20030219      air nz strike to affect australian travellers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dupix2BiHqZZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ff09a4db-71c7-4501-9bdb-f97d1b47f64f"
      },
      "source": [
        "text = data[['headline_text']]\n",
        "text.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aba decides against community broadcasting lic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>act fire witnesses must be aware of defamation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a g calls for infrastructure protection summit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>air nz staff in aust strike for pay rise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>air nz strike to affect australian travellers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       headline_text\n",
              "0  aba decides against community broadcasting lic...\n",
              "1     act fire witnesses must be aware of defamation\n",
              "2     a g calls for infrastructure protection summit\n",
              "3           air nz staff in aust strike for pay rise\n",
              "4      air nz strike to affect australian travellers"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-g8rFaTHt4X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "84717cd8-5507-4409-9639-c2ce20c9414a"
      },
      "source": [
        "import nltk\n",
        "text['headline_text'] = text.apply(lambda row: nltk.word_tokenize(row['headline_text']), axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZCQtHv-Hway",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "571904c7-ee55-43a7-be91-2e9575a37eeb"
      },
      "source": [
        "print(text.head(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                       headline_text\n",
            "0  [aba, decides, against, community, broadcastin...\n",
            "1  [act, fire, witnesses, must, be, aware, of, de...\n",
            "2  [a, g, calls, for, infrastructure, protection,...\n",
            "3  [air, nz, staff, in, aust, strike, for, pay, r...\n",
            "4  [air, nz, strike, to, affect, australian, trav...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYvT1MqhIYh2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "0fe677b1-818a-4251-9369-e5cddfc99c61"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "text['headline_text'] = text['headline_text'].apply(lambda x: [WordNetLemmatizer().lemmatize(word, pos='v') for word in x])\n",
        "print(text.head(5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                       headline_text\n",
            "0  [aba, decide, against, community, broadcast, l...\n",
            "1  [act, fire, witness, must, be, aware, of, defa...\n",
            "2  [a, g, call, for, infrastructure, protection, ...\n",
            "3  [air, nz, staff, in, aust, strike, for, pay, r...\n",
            "4  [air, nz, strike, to, affect, australian, trav...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBmHc9p3IeND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "948a7304-ea4d-4dcb-bc0d-33b7fcb743f9"
      },
      "source": [
        "tokenized_doc = text['headline_text'].apply(lambda x: [word for word in x if len(word) > 3])\n",
        "print(tokenized_doc[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    [decide, against, community, broadcast, licence]\n",
            "1            [fire, witness, must, aware, defamation]\n",
            "2          [call, infrastructure, protection, summit]\n",
            "3                         [staff, aust, strike, rise]\n",
            "4            [strike, affect, australian, travellers]\n",
            "Name: headline_text, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pssi31EJNUU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "b4d65e72-aedf-4f84-eeb0-dda0231b0297"
      },
      "source": [
        "# 역토큰화 (토큰화 작업을 되돌림)\n",
        "detokenized_doc = []\n",
        "for i in range(len(text)):\n",
        "    t = ' '.join(tokenized_doc[i])\n",
        "    detokenized_doc.append(t)\n",
        "\n",
        "text['headline_text'] = detokenized_doc # 다시 text['headline_text']에 재저장"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Inil5nPmJTB7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "1bd1860e-f218-4c0e-a041-ca3f43219e97"
      },
      "source": [
        "text['headline_text'][:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    decide against community broadcast licence\n",
              "1            fire witness must aware defamation\n",
              "2         call infrastructure protection summit\n",
              "3                        staff aust strike rise\n",
              "4           strike affect australian travellers\n",
              "Name: headline_text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WrVjj3qJd6a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee7e97dd-3a6b-4d5f-ac33-717ba1ddfb16"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english', \n",
        "max_features= 1000) # 상위 1,000개의 단어를 보존 \n",
        "X = vectorizer.fit_transform(text['headline_text'])\n",
        "X.shape # TF-IDF 행렬의 크기 확인"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1082168, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFjCJwbGJhtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda_model=LatentDirichletAllocation(n_components=10,learning_method='online',random_state=777,max_iter=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bXjJY5QJmIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_top=lda_model.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoMB7a7EJnl3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "f6b7da1f-8875-429f-e795-c45e713b1ff4"
      },
      "source": [
        "print(lda_model.components_)\n",
        "print(lda_model.components_.shape) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.00001787e-01 1.00001305e-01 1.00004812e-01 ... 1.00006301e-01\n",
            "  1.00004356e-01 1.00002683e-01]\n",
            " [1.00001851e-01 1.13508716e+03 1.00010774e-01 ... 1.00008428e-01\n",
            "  1.00002315e-01 1.00002614e-01]\n",
            " [1.00001547e-01 1.00000897e-01 1.00004252e-01 ... 1.00004055e-01\n",
            "  1.00001757e-01 7.53409554e+02]\n",
            " ...\n",
            " [1.00001119e-01 1.00001828e-01 1.00006994e-01 ... 1.00007152e-01\n",
            "  1.00002998e-01 1.00004489e-01]\n",
            " [1.00002995e-01 1.00000806e-01 1.00004320e-01 ... 1.00003662e-01\n",
            "  1.00001149e-01 1.00004879e-01]\n",
            " [1.00003429e-01 1.00002476e-01 1.00012101e-01 ... 1.00003613e-01\n",
            "  1.00002605e-01 1.00006032e-01]]\n",
            "(10, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABZjB19gKzRL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "a7a7b92a-5e16-414e-ca1c-0f624d0f8464"
      },
      "source": [
        "terms = vectorizer.get_feature_names() # 단어 집합. 1,000개의 단어가 저장됨.\n",
        "\n",
        "def get_topics(components, feature_names, n=5):\n",
        "    for idx, topic in enumerate(components):\n",
        "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(2)) for i in topic.argsort()[:-n - 1:-1]])\n",
        "get_topics(lda_model.components_,terms)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 1: [('government', 8724.47), ('sydney', 8387.49), ('queensland', 7720.29), ('change', 5874.83), ('home', 5670.93)]\n",
            "Topic 2: [('australia', 13692.02), ('australian', 11084.92), ('melbourne', 7525.59), ('world', 6708.04), ('south', 6672.64)]\n",
            "Topic 3: [('interview', 5924.98), ('kill', 5840.58), ('jail', 4627.45), ('life', 4274.88), ('health', 4267.65)]\n",
            "Topic 4: [('house', 6113.7), ('canberra', 6111.84), ('2016', 5488.24), ('state', 4922.6), ('brisbane', 4856.3)]\n",
            "Topic 5: [('court', 7541.27), ('attack', 6957.33), ('perth', 6456.74), ('open', 5660.24), ('face', 5194.16)]\n",
            "Topic 6: [('plan', 6032.03), ('rural', 5503.3), ('death', 4999.48), ('indigenous', 4222.48), ('record', 3986.16)]\n",
            "Topic 7: [('charge', 8425.83), ('election', 7562.16), ('adelaide', 6756.06), ('make', 5658.45), ('market', 5544.54)]\n",
            "Topic 8: [('police', 12081.68), ('crash', 5277.09), ('drug', 4291.01), ('rise', 4044.02), ('beat', 3259.53)]\n",
            "Topic 9: [('labor', 4047.75), ('national', 4038.68), ('council', 4006.73), ('league', 3911.12), ('claim', 3602.39)]\n",
            "Topic 10: [('trump', 11969.61), ('report', 5610.43), ('school', 5463.92), ('woman', 5452.68), ('coast', 5431.43)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl8Bn8tVK0zS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6iBy1PuK3BM",
        "colab_type": "text"
      },
      "source": [
        "# 9장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuPYUTujK4nM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}